# -*- coding: utf-8 -*-
"""nltk ,word_tokenize ,PorterStemmer ,WordNetLemmatizer and stopwords NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gs_1WI5TVnklne0INAzQbOrKzaHtSPEf
"""

import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer ,WordNetLemmatizer
from nltk.corpus import stopwords
import re
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

data =pd.read_csv("/content/drive/MyDrive/tripadvisor_hotel_reviews.csv")
data.head()

data.info()

data['Review'][0]

data['review_lowercase']=data['Review'].str.lower()

data.head()

nltk.download("stopwords")
en_stopwords=stopwords.words('english')

en_stopwords.remove("not")

data['review_no_stopwords']=data['review_lowercase'].apply(lambda x:' '.join([word for word in x.split() if word not in (en_stopwords)]))

data['review_no_stopwords']

data['review_no_stopwords'][0]

data['review_no_stopwords_no_punct']=data.apply(lambda x: re.sub( r"[*]" ,"star" , x['review_no_stopwords']),axis =1)

data.head()

data['review_no_stopwords_no_punct']=data.apply(lambda x: re.sub(r'[*]' ,"star" ,x['review_no_stopwords_no_punct']),axis=1)

data.head()



data['review_no_stopwords_no_punct'][0]

nltk.download('punkt')

data['tokenized'] = data.apply(lambda x: word_tokenize(x['review_no_stopwords_no_punct']), axis=1)

data.head()

data['tokenized'][0]

Ps = PorterStemmer()

data['strmmed']=data['tokenized'].apply(lambda tokens: [Ps.stem(token) for token in tokens])

data.head()

data['strmmed']

data['strmmed'][0]

Lammatizer = WordNetLemmatizer()

nltk.download('averaged_perceptron_tagger')

nltk.download('wordnet')

data['lammtized']=data['tokenized'].apply(lambda tokens: [Lammatizer.lemmatize(token) for token in tokens])

data['lammtized']

data['lammtized'][0]

data.head()

tokens_clean = sum(data['lammtized'], [])

unigrams_ =(pd.Series(nltk.ngrams(tokens_clean , 1)).value_counts())

print(unigrams_)

bgrams_ =(pd.Series(nltk.ngrams(tokens_clean , 2)).value_counts())

print(bgrams_)

unigram =(pd.Series(nltk.ngrams(tokens_clean , 3)).value_counts())

print(unigram)